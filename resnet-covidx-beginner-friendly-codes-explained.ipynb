{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T22:08:39.166677Z",
     "start_time": "2021-11-30T22:08:36.222071Z"
    },
    "execution": {
     "iopub.execute_input": "2021-11-30T19:27:32.595064Z",
     "iopub.status.busy": "2021-11-30T19:27:32.594608Z",
     "iopub.status.idle": "2021-11-30T19:27:40.334411Z",
     "shell.execute_reply": "2021-11-30T19:27:40.333271Z",
     "shell.execute_reply.started": "2021-11-30T19:27:32.594965Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import shutil\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T22:08:42.073447Z",
     "start_time": "2021-11-30T22:08:42.006125Z"
    },
    "execution": {
     "iopub.execute_input": "2021-11-30T19:28:05.178107Z",
     "iopub.status.busy": "2021-11-30T19:28:05.177638Z",
     "iopub.status.idle": "2021-11-30T19:28:05.310739Z",
     "shell.execute_reply": "2021-11-30T19:28:05.309879Z",
     "shell.execute_reply.started": "2021-11-30T19:28:05.178067Z"
    }
   },
   "outputs": [],
   "source": [
    "# we added the separation and header because the data is not organized, one can run without sep and header\n",
    "#to understand the difference\n",
    "\n",
    "train_df = pd.read_csv('train.txt', sep=\" \", header=None)\n",
    "\n",
    "#Columns are added because it was seen that column names were 0,1,2,3, so new column names are added\n",
    "#which are given in descriptions\n",
    "train_df.columns=['patient id', 'filename', 'class', 'data source']\n",
    "\n",
    "# Since we are doing image classification, patient id and data source is of no importance to us, so\n",
    "#we cn drop them\n",
    "train_df=train_df.drop(['patient id', 'data source'], axis=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same for test set!\n",
    "\n",
    "I highly encourage beginners to read the data without sep and header parameters to understand the difference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T22:08:43.758148Z",
     "start_time": "2021-11-30T22:08:43.749345Z"
    },
    "execution": {
     "iopub.execute_input": "2021-11-30T19:28:08.79926Z",
     "iopub.status.busy": "2021-11-30T19:28:08.798639Z",
     "iopub.status.idle": "2021-11-30T19:28:08.819048Z",
     "shell.execute_reply": "2021-11-30T19:28:08.818048Z",
     "shell.execute_reply.started": "2021-11-30T19:28:08.79921Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#same as train\n",
    "test_df = pd.read_csv('test.txt', sep=\" \", header=None)\n",
    "test_df.columns=['id', 'filename', 'class', 'data source' ]\n",
    "test_df=test_df.drop(['id', 'data source'], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T22:08:44.523857Z",
     "start_time": "2021-11-30T22:08:44.511647Z"
    },
    "execution": {
     "iopub.execute_input": "2021-11-30T19:28:46.778212Z",
     "iopub.status.busy": "2021-11-30T19:28:46.777823Z",
     "iopub.status.idle": "2021-11-30T19:28:46.789163Z",
     "shell.execute_reply": "2021-11-30T19:28:46.78817Z",
     "shell.execute_reply.started": "2021-11-30T19:28:46.778176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARDSSevere.png</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acute-respiratory-distress-syndrome-ards-1.jpg</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acute-respiratory-distress-syndrome-ards.jpg</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ards-secondary-to-tiger-snake-bite.png</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pneumocystis-pneumonia-2-PA.png</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         filename     class\n",
       "0                                  ARDSSevere.png  negative\n",
       "1  acute-respiratory-distress-syndrome-ards-1.jpg  negative\n",
       "2    acute-respiratory-distress-syndrome-ards.jpg  negative\n",
       "3          ards-secondary-to-tiger-snake-bite.png  negative\n",
       "4                 pneumocystis-pneumonia-2-PA.png  negative"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head() # see the first 5 rows and columns of train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T22:08:45.112620Z",
     "start_time": "2021-11-30T22:08:45.104366Z"
    },
    "execution": {
     "iopub.execute_input": "2021-11-30T19:28:47.190839Z",
     "iopub.status.busy": "2021-11-30T19:28:47.190438Z",
     "iopub.status.idle": "2021-11-30T19:28:47.201524Z",
     "shell.execute_reply": "2021-11-30T19:28:47.200223Z",
     "shell.execute_reply.started": "2021-11-30T19:28:47.190804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MIDRC-RICORD-1C-419639-003251-46647-0.png</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MIDRC-RICORD-1C-419639-001464-39871-0.png</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MIDRC-RICORD-1C-419639-000918-78965-0.png</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MIDRC-RICORD-1C-419639-003318-64285-0.png</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MIDRC-RICORD-1C-419639-001015-81591-0.png</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    filename     class\n",
       "0  MIDRC-RICORD-1C-419639-003251-46647-0.png  positive\n",
       "1  MIDRC-RICORD-1C-419639-001464-39871-0.png  positive\n",
       "2  MIDRC-RICORD-1C-419639-000918-78965-0.png  positive\n",
       "3  MIDRC-RICORD-1C-419639-003318-64285-0.png  positive\n",
       "4  MIDRC-RICORD-1C-419639-001015-81591-0.png  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()#see the first 5 columns for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T22:08:45.438582Z",
     "start_time": "2021-11-30T22:08:45.435617Z"
    },
    "execution": {
     "iopub.execute_input": "2021-11-30T19:28:53.68878Z",
     "iopub.status.busy": "2021-11-30T19:28:53.688102Z",
     "iopub.status.idle": "2021-11-30T19:28:53.694181Z",
     "shell.execute_reply": "2021-11-30T19:28:53.692839Z",
     "shell.execute_reply.started": "2021-11-30T19:28:53.688713Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = 'train/'  #directory path\n",
    "test_path = 'test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T22:08:45.684821Z",
     "start_time": "2021-11-30T22:08:45.674988Z"
    },
    "execution": {
     "iopub.execute_input": "2021-11-30T19:28:58.031799Z",
     "iopub.status.busy": "2021-11-30T19:28:58.031186Z",
     "iopub.status.idle": "2021-11-30T19:28:58.050339Z",
     "shell.execute_reply": "2021-11-30T19:28:58.049231Z",
     "shell.execute_reply.started": "2021-11-30T19:28:58.031737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    16490\n",
       "negative    13992\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the negative values are 13793 and positive values are 2158.\n",
    "\n",
    "We need to balance them, else the model we create will be more biased towards negative and thereby wrong predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T22:08:46.232261Z",
     "start_time": "2021-11-30T22:08:46.229163Z"
    },
    "execution": {
     "iopub.execute_input": "2021-11-30T19:32:25.540827Z",
     "iopub.status.busy": "2021-11-30T19:32:25.540344Z",
     "iopub.status.idle": "2021-11-30T19:32:25.562356Z",
     "shell.execute_reply": "2021-11-30T19:32:25.561064Z",
     "shell.execute_reply.started": "2021-11-30T19:32:25.540776Z"
    }
   },
   "outputs": [],
   "source": [
    "# negative  = train_df[train_df['class']=='negative']   #negative values in class column\n",
    "# positive = train_df[train_df['class']=='positive']  #positive values in class column\n",
    "# from sklearn.utils import resample\n",
    "# #majority class that  is negative, we need to downsample/decrease that class so that there is no bias\n",
    "# #n_samples = 2158 means we want 2158 sample of class negative, since there are 2158 samples of class positive\n",
    "# df_majority_downsampled = resample(negative, replace = True, n_samples = 2158) \n",
    "# #concatenate\n",
    "# train_df = pd.concat([positive, df_majority_downsampled])\n",
    "\n",
    "# from sklearn.utils import shuffle\n",
    "# train_df = shuffle(train_df) # shuffling so that there is particular sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T22:08:46.742481Z",
     "start_time": "2021-11-30T22:08:46.732056Z"
    },
    "execution": {
     "iopub.execute_input": "2021-11-30T19:32:25.850153Z",
     "iopub.status.busy": "2021-11-30T19:32:25.849747Z",
     "iopub.status.idle": "2021-11-30T19:32:25.863804Z",
     "shell.execute_reply": "2021-11-30T19:32:25.862517Z",
     "shell.execute_reply.started": "2021-11-30T19:32:25.850119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    16490\n",
       "negative    13992\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Now no imbalanced data! Proceed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will split the train data into train(for training the model) and valid(for validation) and then after training and validation we will use the model to predict on test set. Simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T22:08:47.077604Z",
     "start_time": "2021-11-30T22:08:47.065539Z"
    },
    "execution": {
     "iopub.execute_input": "2021-11-30T19:32:29.256031Z",
     "iopub.status.busy": "2021-11-30T19:32:29.255435Z",
     "iopub.status.idle": "2021-11-30T19:32:29.264558Z",
     "shell.execute_reply": "2021-11-30T19:32:29.263287Z",
     "shell.execute_reply.started": "2021-11-30T19:32:29.255987Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(train_df, train_size=0.9, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T22:08:47.283586Z",
     "start_time": "2021-11-30T22:08:47.273955Z"
    },
    "execution": {
     "iopub.execute_input": "2021-11-30T19:32:51.415863Z",
     "iopub.status.busy": "2021-11-30T19:32:51.415279Z",
     "iopub.status.idle": "2021-11-30T19:32:51.433889Z",
     "shell.execute_reply": "2021-11-30T19:32:51.433113Z",
     "shell.execute_reply.started": "2021-11-30T19:32:51.415804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative and positive values of train: positive    14830\n",
      "negative    12603\n",
      "Name: class, dtype: int64\n",
      "Negative and positive values of validation: positive    1660\n",
      "negative    1389\n",
      "Name: class, dtype: int64\n",
      "Negative and positive values of test: positive    200\n",
      "negative    200\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Let's see how many images for training and validation and testing\n",
    "\n",
    "print(f\"Negative and positive values of train: {train_df['class'].value_counts()}\")\n",
    "print(f\"Negative and positive values of validation: {valid_df['class'].value_counts()}\")\n",
    "print(f\"Negative and positive values of test: {test_df['class'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T22:08:47.680078Z",
     "start_time": "2021-11-30T22:08:47.501343Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-20T01:56:43.773385Z",
     "iopub.status.busy": "2021-06-20T01:56:43.772812Z",
     "iopub.status.idle": "2021-06-20T01:56:46.854187Z",
     "shell.execute_reply": "2021-06-20T01:56:46.853055Z",
     "shell.execute_reply.started": "2021-06-20T01:56:43.773349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27433 validated image filenames belonging to 2 classes.\n",
      "Found 3049 validated image filenames belonging to 2 classes.\n",
      "Found 400 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Let's start the modelling task\n",
    "# The ImageDataGenerator for keras is awesome.\n",
    "#It lets you augment your images in real-time while your model is still training! \n",
    "#You can apply any random transformations on each training image as it is passed to the model. \n",
    "#This will not only make your model robust but will also save up on the overhead memory!\n",
    "\n",
    "\n",
    "#We will apply the Image Data Generator on training with various parameters, but we won't apply \n",
    "#the same parameters on testin. Why?\n",
    "# Because we want the test iamges as it is, we don't want biasedness,\n",
    "#also if we fit it we will be applying\n",
    "# the model only on these test images only, it can't predict new images if fed into model\n",
    "#Because new images will not be augmented this way\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, \n",
    "                                   shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True, vertical_flip =True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "\n",
    "#Now fit the them to get the images from directory (name of the images are given in dataframe) with augmentation\n",
    "\n",
    "\n",
    "train_gen = train_datagen.flow_from_dataframe(dataframe = train_df, directory=train_path, x_col='filename', \n",
    "                                              y_col='class', target_size=(200,200), batch_size=64, \n",
    "                                               class_mode='binary')\n",
    "valid_gen = test_datagen.flow_from_dataframe(dataframe = valid_df, directory=train_path, x_col='filename',\n",
    "                                             y_col='class', target_size=(200,200), batch_size=64, \n",
    "                                            class_mode='binary')\n",
    "test_gen = test_datagen.flow_from_dataframe(dataframe = test_df, directory=test_path, x_col='filename', \n",
    "                                            y_col='class', target_size=(200,200), batch_size=64,\n",
    "                                             class_mode='binary')\n",
    "#class mode binary because we want the classifier to predict covid or not\n",
    "#target size (200,200) means we want the images to resized to 200*200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now start the transfer learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T22:08:49.368812Z",
     "start_time": "2021-11-30T22:08:48.712863Z"
    },
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-06-20T01:56:46.855755Z",
     "iopub.status.busy": "2021-06-20T01:56:46.855421Z",
     "iopub.status.idle": "2021-06-20T01:56:52.385742Z",
     "shell.execute_reply": "2021-06-20T01:56:52.384897Z",
     "shell.execute_reply.started": "2021-06-20T01:56:46.855719Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v1/d7hv9mbs335bshjjrrhv0ms00000gn/T/ipykernel_14423/1463562956.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Our base model is InceptionResNetV2, new readers are encouraged to see the architecture of this particular model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m base_model = tf.keras.applications.ResNet50V2(weights='imagenet', input_shape = (200,200,3),\n\u001b[0m\u001b[1;32m      5\u001b[0m                                                      include_top=False)\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/base2/lib/python3.8/site-packages/tensorflow/python/keras/applications/resnet_v2.py\u001b[0m in \u001b[0;36mResNet50V2\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   return resnet.ResNet(\n\u001b[0m\u001b[1;32m     49\u001b[0m       \u001b[0mstack_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/base2/lib/python3.8/site-packages/tensorflow/python/keras/applications/resnet.py\u001b[0m in \u001b[0;36mResNet\u001b[0;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mcache_subdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         file_hash=file_hash)\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/base2/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2232\u001b[0m             f, self.layers, skip_mismatch=skip_mismatch)\n\u001b[1;32m   2233\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2234\u001b[0;31m         \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/base2/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    660\u001b[0m   \"\"\"\n\u001b[1;32m    661\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m'keras_version'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m     \u001b[0moriginal_keras_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keras_version'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m     \u001b[0moriginal_keras_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#Our base model is InceptionResNetV2, new readers are encouraged to see the architecture of this particular model\n",
    "\n",
    "base_model = tf.keras.applications.ResNet50V2(weights='imagenet', input_shape = (200,200,3),\n",
    "                                                     include_top=False)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T22:08:51.930867Z",
     "start_time": "2021-11-30T22:08:51.901948Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-20T01:56:52.387315Z",
     "iopub.status.busy": "2021-06-20T01:56:52.386964Z",
     "iopub.status.idle": "2021-06-20T01:56:52.765431Z",
     "shell.execute_reply": "2021-06-20T01:56:52.764584Z",
     "shell.execute_reply.started": "2021-06-20T01:56:52.387279Z"
    }
   },
   "outputs": [],
   "source": [
    "#Now we will add some more layers to the base model for our requirements\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "#     base_model, \n",
    "    tf.keras.layers.GlobalAveragePooling2D(), \n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(), \n",
    "    tf.keras.layers.Dropout(0.2), \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"covid_classifier_model.h5\", save_best_only=True, verbose = 0),\n",
    "    tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss', verbose=1),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n",
    "]\n",
    "\n",
    "model.compile(optimizer = keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-11-30T22:08:57.933Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-20T01:56:52.766929Z",
     "iopub.status.busy": "2021-06-20T01:56:52.766592Z",
     "iopub.status.idle": "2021-06-20T02:15:58.564545Z",
     "shell.execute_reply": "2021-06-20T02:15:58.563626Z",
     "shell.execute_reply.started": "2021-06-20T01:56:52.766894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2ab25e3a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2ab25e3a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 01:08:58.849475: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-12-01 01:08:58.850198: W tensorflow/core/platform/profile_utils/cpu_utils.cc:126] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 71/429 [===>..........................] - ETA: 4:43 - loss: 0.6995 - accuracy: 0.5025"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_gen, \n",
    "                    validation_data=valid_gen, epochs=20, \n",
    "                    callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-11-30T22:07:02.474Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-20T02:15:58.566892Z",
     "iopub.status.busy": "2021-06-20T02:15:58.566251Z",
     "iopub.status.idle": "2021-06-20T02:16:39.034755Z",
     "shell.execute_reply": "2021-06-20T02:16:39.033974Z",
     "shell.execute_reply.started": "2021-06-20T02:15:58.56685Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights('./covid_classifier_model.h5')\n",
    "model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-06-20T02:16:39.036654Z",
     "iopub.status.busy": "2021-06-20T02:16:39.03604Z",
     "iopub.status.idle": "2021-06-20T02:17:02.618174Z",
     "shell.execute_reply": "2021-06-20T02:17:02.617375Z",
     "shell.execute_reply.started": "2021-06-20T02:16:39.036615Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = (model.predict(test_gen)>0.5).astype(\"int32\")\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you like it ot fork it, then upvote it! This gives us motivation to produce more notebooks for the community!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
