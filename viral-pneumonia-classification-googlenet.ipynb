{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Virus Classification**\n",
    "\n",
    "+ **Datasets**: chest-xray-pneumonia + covidx-cxr2\n",
    "\n",
    "+ **Classes**: Normal, Pneumonia, Covid_19\n",
    "\n",
    "+ **Models**: GoogLeNet, DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T22:11:42.582551Z",
     "start_time": "2021-11-30T22:11:42.109347Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-26T14:29:07.779553Z",
     "iopub.status.busy": "2021-07-26T14:29:07.778805Z",
     "iopub.status.idle": "2021-07-26T14:29:07.80678Z",
     "shell.execute_reply": "2021-07-26T14:29:07.805819Z",
     "shell.execute_reply.started": "2021-07-26T14:29:07.779463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macOS-11.6.1-arm64-arm-64bit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '73'\n",
    "\n",
    "seed = 73\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "print(platform.platform())\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T22:11:43.308079Z",
     "start_time": "2021-11-30T22:11:43.171063Z"
    },
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2021-07-26T14:29:07.845281Z",
     "iopub.status.busy": "2021-07-26T14:29:07.844305Z",
     "iopub.status.idle": "2021-07-26T14:29:08.590896Z",
     "shell.execute_reply": "2021-07-26T14:29:08.589832Z",
     "shell.execute_reply.started": "2021-07-26T14:29:07.845232Z"
    },
    "id": "On5ksz2vclUc",
    "outputId": "3c4e95f9-0fdc-4396-a8ad-eabaf8f1af2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-30T22:11:44.112159Z",
     "start_time": "2021-11-30T22:11:43.974291Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-26T14:29:08.593086Z",
     "iopub.status.busy": "2021-07-26T14:29:08.592652Z",
     "iopub.status.idle": "2021-07-26T14:29:09.357893Z",
     "shell.execute_reply": "2021-07-26T14:29:09.356933Z",
     "shell.execute_reply.started": "2021-07-26T14:29:08.59304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: /kaggle/input/: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T14:29:09.360077Z",
     "iopub.status.busy": "2021-07-26T14:29:09.359703Z",
     "iopub.status.idle": "2021-07-26T14:29:09.37666Z",
     "shell.execute_reply": "2021-07-26T14:29:09.375719Z",
     "shell.execute_reply.started": "2021-07-26T14:29:09.360039Z"
    },
    "id": "iBE8NNODqVtn",
    "outputId": "50db6aa2-9ed6-4f4b-9090-8beb7efc59a7"
   },
   "outputs": [],
   "source": [
    "MyDrive = '/kaggle/working'\n",
    "clear_output()\n",
    "\n",
    "DataDir = '../input/covidx-cxr2'\n",
    "PneumoniaDir = '../input/chest-xray-pneumonia/chest_xray'\n",
    "\n",
    "print('> Covid 19 dir:', os.listdir(DataDir))\n",
    "print('> Pneumonia dir:', os.listdir(PneumoniaDir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T14:29:09.38134Z",
     "iopub.status.busy": "2021-07-26T14:29:09.380911Z",
     "iopub.status.idle": "2021-07-26T14:29:09.471551Z",
     "shell.execute_reply": "2021-07-26T14:29:09.47071Z",
     "shell.execute_reply.started": "2021-07-26T14:29:09.381304Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train_image_dir = PneumoniaDir + '/train'\n",
    "test_image_dir = PneumoniaDir + '/test'\n",
    "val_image_dir = PneumoniaDir + '/val'\n",
    "\n",
    "img_map = []\n",
    "\n",
    "def prepareData(Dir, strat):\n",
    "    cats = [\"NORMAL\",\"PNEUMONIA\"]\n",
    "    for category in cats:\n",
    "        path = os.path.join(Dir,category)\n",
    "        class_num = cats.index(category)\n",
    "        \n",
    "        for img in tqdm(os.listdir(path)):\n",
    "            img_path = os.path.join(path,img)\n",
    "            img_map.append({'path': img_path, 'label': category})\n",
    "\n",
    "prepareData(train_image_dir,'train')\n",
    "prepareData(test_image_dir,'test')\n",
    "prepareData(val_image_dir, 'val')\n",
    "\n",
    "img_map = pd.DataFrame(img_map).sample(frac = 1, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Getting image path and labels from *.txt files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2021-07-26T14:29:09.473162Z",
     "iopub.status.busy": "2021-07-26T14:29:09.47273Z",
     "iopub.status.idle": "2021-07-26T14:29:09.484405Z",
     "shell.execute_reply": "2021-07-26T14:29:09.483493Z",
     "shell.execute_reply.started": "2021-07-26T14:29:09.473122Z"
    }
   },
   "outputs": [],
   "source": [
    "#ricord, rsna, cohen, actmed, sirm, \n",
    "def getClass(label):\n",
    "    if label == 'negative':\n",
    "        return 'NORMAL'\n",
    "    if label == 'positive':\n",
    "        return 'COVID'\n",
    "\n",
    "def get_image_map(txt_path, strat):\n",
    "    train_txt = open(txt_path, 'r')\n",
    "    Lines = train_txt.readlines()\n",
    "    paths = []\n",
    "    \n",
    "    img_formats = ['jpg', 'jpeg', 'png']\n",
    "    \n",
    "    for n, line in enumerate(Lines):\n",
    "        querywords = line.split()\n",
    "\n",
    "        if len(querywords) == 4:\n",
    "            image_id = querywords[0]\n",
    "            image_path = DataDir + '/' + strat + '/'+ querywords[1]\n",
    "            label = querywords[2]\n",
    "\n",
    "        if len(querywords) == 5:\n",
    "            image_id = querywords[0]\n",
    "            image_path = DataDir + '/' + strat + '/'+ querywords[2]\n",
    "            label = querywords[3]\n",
    "            \n",
    "        for img_type in img_formats:\n",
    "            if img_type in line:\n",
    "                obj_ = {'path': image_path, 'label': getClass(label)}\n",
    "                if (('positive' in line) | ('negative' in line)):\n",
    "                    paths.append(obj_)\n",
    "\n",
    "    paths_df = pd.DataFrame(paths)\n",
    "    return paths_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T14:29:09.488491Z",
     "iopub.status.busy": "2021-07-26T14:29:09.488143Z",
     "iopub.status.idle": "2021-07-26T14:29:09.557828Z",
     "shell.execute_reply": "2021-07-26T14:29:09.556907Z",
     "shell.execute_reply.started": "2021-07-26T14:29:09.488464Z"
    }
   },
   "outputs": [],
   "source": [
    "train_map = get_image_map(DataDir + '/train.txt', \n",
    "                          strat='train').sample(frac = 1, random_state=73)\n",
    "\n",
    "test_map = get_image_map(DataDir + '/test.txt',\n",
    "                         strat='test').sample(frac = 1, random_state=73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T14:29:09.560083Z",
     "iopub.status.busy": "2021-07-26T14:29:09.55979Z",
     "iopub.status.idle": "2021-07-26T14:29:09.580199Z",
     "shell.execute_reply": "2021-07-26T14:29:09.579243Z",
     "shell.execute_reply.started": "2021-07-26T14:29:09.560058Z"
    }
   },
   "outputs": [],
   "source": [
    "img_path_map = pd.concat([img_map, train_map, test_map], axis=0).sample(frac = 1, random_state=73)\n",
    "img_path_map.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T14:29:09.581944Z",
     "iopub.status.busy": "2021-07-26T14:29:09.581605Z",
     "iopub.status.idle": "2021-07-26T14:29:11.751913Z",
     "shell.execute_reply": "2021-07-26T14:29:11.751092Z",
     "shell.execute_reply.started": "2021-07-26T14:29:09.58191Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def print_images(samples): \n",
    "    images = samples[\"path\"].to_numpy()\n",
    "    labels = samples['label'].to_numpy()\n",
    "    \n",
    "    fig=plt.figure(figsize=(20, 8))\n",
    "    columns = 4\n",
    "    rows = 1\n",
    "    \n",
    "    for i, image_path in enumerate(images):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        \n",
    "        fig.add_subplot(rows,columns,i + 1)\n",
    "        title = '{}'.format(labels[i])\n",
    "        \n",
    "        Sample_image = cv2.resize(image, (224, 224), interpolation = cv2.INTER_CUBIC)\n",
    "        \n",
    "        plt.imshow(Sample_image, cmap='gray')\n",
    "        plt.title(title)\n",
    "        \n",
    "    plt.show()\n",
    "        \n",
    "print_images(img_path_map[img_path_map['label']==\"NORMAL\"].iloc[0:4])\n",
    "print_images(img_path_map[img_path_map['label']==\"PNEUMONIA\"].iloc[0:4])\n",
    "print_images(img_path_map[img_path_map['label']==\"COVID\"].iloc[0:4])\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2021-07-26T14:29:11.753845Z",
     "iopub.status.busy": "2021-07-26T14:29:11.753303Z",
     "iopub.status.idle": "2021-07-26T14:29:11.772176Z",
     "shell.execute_reply": "2021-07-26T14:29:11.770977Z",
     "shell.execute_reply.started": "2021-07-26T14:29:11.753799Z"
    }
   },
   "outputs": [],
   "source": [
    "def getLabelCount(frame):\n",
    "    label_count = pd.Series(frame['label'].values.ravel()).value_counts()\n",
    "    n_classes = (label_count)\n",
    "    return label_count\n",
    "\n",
    "label_count = getLabelCount(img_path_map)\n",
    "print(label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T14:29:11.774329Z",
     "iopub.status.busy": "2021-07-26T14:29:11.773831Z",
     "iopub.status.idle": "2021-07-26T14:29:12.203156Z",
     "shell.execute_reply": "2021-07-26T14:29:12.202183Z",
     "shell.execute_reply.started": "2021-07-26T14:29:11.774282Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "features = img_path_map['path'].to_numpy()\n",
    "labels = img_path_map['label'].to_numpy()\n",
    "\n",
    "stratified_sample = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T14:29:12.204795Z",
     "iopub.status.busy": "2021-07-26T14:29:12.204416Z",
     "iopub.status.idle": "2021-07-26T14:29:12.271985Z",
     "shell.execute_reply": "2021-07-26T14:29:12.271261Z",
     "shell.execute_reply.started": "2021-07-26T14:29:12.204758Z"
    }
   },
   "outputs": [],
   "source": [
    "for train_index, test_index in stratified_sample.split(features, labels):\n",
    "    X_train, test_X = features[train_index], features[test_index]\n",
    "    y_train, test_y = labels[train_index], labels[test_index]\n",
    "    \n",
    "half_size = np.int(len(test_X) / 2)\n",
    "X_test, y_test = test_X[0:half_size], test_y[0:half_size]\n",
    "X_val, y_val = test_X[half_size:], test_y[half_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T14:29:12.273712Z",
     "iopub.status.busy": "2021-07-26T14:29:12.27334Z",
     "iopub.status.idle": "2021-07-26T14:29:12.283577Z",
     "shell.execute_reply": "2021-07-26T14:29:12.282193Z",
     "shell.execute_reply.started": "2021-07-26T14:29:12.273676Z"
    }
   },
   "outputs": [],
   "source": [
    "train_map = pd.DataFrame()\n",
    "train_map['path'], train_map['label'] = X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T14:29:12.285893Z",
     "iopub.status.busy": "2021-07-26T14:29:12.285434Z",
     "iopub.status.idle": "2021-07-26T14:29:12.29607Z",
     "shell.execute_reply": "2021-07-26T14:29:12.295079Z",
     "shell.execute_reply.started": "2021-07-26T14:29:12.285852Z"
    }
   },
   "outputs": [],
   "source": [
    "test_map = pd.DataFrame()\n",
    "test_map['path'], test_map['label'] = X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T14:29:12.297983Z",
     "iopub.status.busy": "2021-07-26T14:29:12.297525Z",
     "iopub.status.idle": "2021-07-26T14:29:12.308131Z",
     "shell.execute_reply": "2021-07-26T14:29:12.30709Z",
     "shell.execute_reply.started": "2021-07-26T14:29:12.297941Z"
    }
   },
   "outputs": [],
   "source": [
    "val_map = pd.DataFrame()\n",
    "val_map['path'], val_map['label'] = X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T14:29:12.312209Z",
     "iopub.status.busy": "2021-07-26T14:29:12.311722Z",
     "iopub.status.idle": "2021-07-26T14:29:12.320543Z",
     "shell.execute_reply": "2021-07-26T14:29:12.319722Z",
     "shell.execute_reply.started": "2021-07-26T14:29:12.312176Z"
    }
   },
   "outputs": [],
   "source": [
    "# data summary\n",
    "print('> {} train size'.format(X_train.shape[0]))\n",
    "print('> {} test size'.format(X_test.shape[0]))\n",
    "print('> {} val size'.format(X_val.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T14:29:12.322321Z",
     "iopub.status.busy": "2021-07-26T14:29:12.321939Z",
     "iopub.status.idle": "2021-07-26T14:29:12.632024Z",
     "shell.execute_reply": "2021-07-26T14:29:12.630985Z",
     "shell.execute_reply.started": "2021-07-26T14:29:12.322285Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import imageio\n",
    "import imgaug.augmenters as iaa\n",
    "import imgaug as ia\n",
    "ia.seed(73)\n",
    "\n",
    "ColorCh = 3\n",
    "IMG_SIZE = 224\n",
    "input_shape=(IMG_SIZE, IMG_SIZE, ColorCh)\n",
    "\n",
    "classes = (\"COVID\", \"NORMAL\",\"PNEUMONIA\")\n",
    "CATEGORIES = sorted(classes)\n",
    "\n",
    "print('> Classes:',CATEGORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T14:29:12.634081Z",
     "iopub.status.busy": "2021-07-26T14:29:12.633484Z",
     "iopub.status.idle": "2021-07-26T14:29:14.203152Z",
     "shell.execute_reply": "2021-07-26T14:29:14.202272Z",
     "shell.execute_reply.started": "2021-07-26T14:29:12.634037Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "\n",
    "datagen = ImageDataGenerator(rescale = 1./255, \n",
    "                             horizontal_flip=True,\n",
    "                             brightness_range=[1.0,1.3],\n",
    "                             rotation_range=15,\n",
    "                             #zoom_range=0.2\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T14:29:14.204982Z",
     "iopub.status.busy": "2021-07-26T14:29:14.204478Z",
     "iopub.status.idle": "2021-07-26T14:29:14.210705Z",
     "shell.execute_reply": "2021-07-26T14:29:14.209688Z",
     "shell.execute_reply.started": "2021-07-26T14:29:14.204943Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def get_generator(frame_):\n",
    "    generator = datagen.flow_from_dataframe(\n",
    "                          dataframe=frame_,\n",
    "                          x_col=\"path\",\n",
    "                          y_col=\"label\",\n",
    "                          batch_size=batch_size,\n",
    "                          seed=seed,\n",
    "                          shuffle=False,\n",
    "                          class_mode=\"sparse\",\n",
    "                          color_mode=\"rgb\",\n",
    "                          save_format=\"jpeg\",\n",
    "                          target_size=(IMG_SIZE,IMG_SIZE)             \n",
    "             )\n",
    "    \n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2021-07-26T14:29:14.212574Z",
     "iopub.status.busy": "2021-07-26T14:29:14.212181Z",
     "iopub.status.idle": "2021-07-26T14:29:41.444289Z",
     "shell.execute_reply": "2021-07-26T14:29:41.443463Z",
     "shell.execute_reply.started": "2021-07-26T14:29:14.21254Z"
    },
    "id": "TvMUmPxWM_Sw",
    "outputId": "a9628e82-66a7-4d17-a85e-eeb3044aabbf"
   },
   "outputs": [],
   "source": [
    "train_df = train_map.sample(frac=1, random_state=seed)\n",
    "train_generator = get_generator(train_df)\n",
    "\n",
    "print('> label count for train set')\n",
    "getLabelCount(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T14:29:41.445969Z",
     "iopub.status.busy": "2021-07-26T14:29:41.44562Z",
     "iopub.status.idle": "2021-07-26T14:29:44.802258Z",
     "shell.execute_reply": "2021-07-26T14:29:44.801458Z",
     "shell.execute_reply.started": "2021-07-26T14:29:41.44593Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = test_map.sample(frac=1, random_state=seed)\n",
    "test_generator = get_generator(test_df)\n",
    "\n",
    "print('> label count for test set')\n",
    "getLabelCount(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T14:29:44.80567Z",
     "iopub.status.busy": "2021-07-26T14:29:44.805389Z",
     "iopub.status.idle": "2021-07-26T14:29:47.931452Z",
     "shell.execute_reply": "2021-07-26T14:29:47.930426Z",
     "shell.execute_reply.started": "2021-07-26T14:29:44.805641Z"
    }
   },
   "outputs": [],
   "source": [
    "val_df = val_map.sample(frac=1, random_state=seed)\n",
    "val_generator = get_generator(val_df)\n",
    "\n",
    "print('> label count for val set')\n",
    "getLabelCount(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T14:29:47.93339Z",
     "iopub.status.busy": "2021-07-26T14:29:47.932977Z",
     "iopub.status.idle": "2021-07-26T14:29:47.938429Z",
     "shell.execute_reply": "2021-07-26T14:29:47.937571Z",
     "shell.execute_reply.started": "2021-07-26T14:29:47.933349Z"
    }
   },
   "outputs": [],
   "source": [
    "print('> input shape:', input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Building Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2021-07-26T14:29:47.940574Z",
     "iopub.status.busy": "2021-07-26T14:29:47.939953Z",
     "iopub.status.idle": "2021-07-26T14:29:47.949545Z",
     "shell.execute_reply": "2021-07-26T14:29:47.948552Z",
     "shell.execute_reply.started": "2021-07-26T14:29:47.940537Z"
    },
    "id": "E8zlJ-GQYyv1"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Add, add\n",
    "from tensorflow.keras.layers import InputLayer, Input, Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, Activation, MaxPool2D, ZeroPadding2D, SeparableConv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from keras import regularizers\n",
    "\n",
    "kernel_regularizer = regularizers.l2(0.0001)\n",
    "\n",
    "final_activation = 'softmax'\n",
    "entropy = 'sparse_categorical_crossentropy'\n",
    "n_classes = len(CATEGORIES)\n",
    "print('> {} classes'.format(n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T14:29:47.9515Z",
     "iopub.status.busy": "2021-07-26T14:29:47.950886Z",
     "iopub.status.idle": "2021-07-26T14:29:47.957846Z",
     "shell.execute_reply": "2021-07-26T14:29:47.956704Z",
     "shell.execute_reply.started": "2021-07-26T14:29:47.951463Z"
    }
   },
   "outputs": [],
   "source": [
    "def FCLayers(baseModel):\n",
    "    baseModel.trainable = True\n",
    "    headModel = baseModel.output\n",
    "    headModel = Dropout(0.5, seed=73)(headModel)\n",
    "    headModel = Dense(n_classes, activation=final_activation)(headModel)\n",
    "    model = Model(inputs = baseModel.input, outputs = headModel)\n",
    "    5\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **GoogLenet**\n",
    "\n",
    "**Blog Reference**: https://medium.com/mlearning-ai/implementation-of-googlenet-on-keras-d9873aeed83c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Inception Block**\n",
    "\n",
    "![](https://miro.medium.com/max/2400/1*zIcot5nm9q_TC8zqcGQ7Dg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.merge import concatenate\n",
    "\n",
    "def Inception_block(input_layer, f1, f2, f3, f4):    \n",
    "    \n",
    "    path1 = Conv2D(filters=f1, kernel_size = (1,1), padding = 'same', activation = 'relu')(input_layer)\n",
    "    \n",
    "    path2 = Conv2D(filters = f2[0], kernel_size = (1,1), \n",
    "                   padding = 'same', activation = 'relu')(input_layer)\n",
    "    \n",
    "    path2 = Conv2D(filters = f2[1], kernel_size = (3,3), \n",
    "                   padding = 'same', activation = 'relu')(path2)\n",
    "\n",
    "    path3 = Conv2D(filters = f3[0], kernel_size = (1,1), \n",
    "                   padding = 'same', activation = 'relu')(input_layer)\n",
    "    \n",
    "    path3 = Conv2D(filters = f3[1], kernel_size = (5,5), \n",
    "                   padding = 'same', activation = 'relu')(path3)\n",
    "\n",
    "    path4 = MaxPooling2D((3,3), strides= (1,1), \n",
    "                         padding = 'same')(input_layer)\n",
    "    \n",
    "    path4 = Conv2D(filters = f4, kernel_size = (1,1), \n",
    "                   padding = 'same', activation = 'relu')(path4)\n",
    "    \n",
    "    output_layer = concatenate([path1, path2, path3, path4], axis = -1)\n",
    "\n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxHy0dxMtqlk"
   },
   "source": [
    "![](https://miro.medium.com/max/664/1*4nb4lVJnaKJZAu6Lthuz2Q.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary_classifiers\n",
    "def Extra_network_2(X):\n",
    "    X2 = AveragePooling2D(pool_size = (5,5), strides = 3)(X)\n",
    "    X2 = Conv2D(filters = 128, kernel_size = (1,1), \n",
    "                padding = 'same', activation = 'relu')(X2)\n",
    "    \n",
    "    X2 = Flatten()(X2)\n",
    "    X2 = Dense(1024, activation = 'relu')(X2)\n",
    "    X2 = Dropout(0.5)(X2)\n",
    "    X2 = Dense(n_classes, activation = final_activation, name=\"output2\")(X2)\n",
    "    return X2\n",
    "\n",
    "\n",
    "def Extra_network_1(X):\n",
    "    X1 = AveragePooling2D(pool_size = (5,5), strides = 3)(X)\n",
    "    X1 = Conv2D(filters = 128, kernel_size = (1,1), \n",
    "                padding = 'same', activation = 'relu')(X1)\n",
    "    \n",
    "    X1 = Flatten()(X1)\n",
    "    X1 = Dense(1024, activation = 'relu')(X1)\n",
    "    X1 = Dropout(0.5)(X1)\n",
    "    X1 = Dense(n_classes, activation = final_activation, name=\"output1\")(X1)\n",
    "    return X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_4(X):\n",
    "    X = Inception_block(X, 192, (96, 208) , (16, 48), 64)\n",
    "    \n",
    "    X1 = Extra_network_1(X)\n",
    "    \n",
    "    X = Inception_block(X, 160, (112, 224), (24, 64), 64)\n",
    "    X = Inception_block(X, 128, (128, 256), (24, 64), 64)\n",
    "    X = Inception_block(X, 112, (144, 288), (32, 64), 64)\n",
    "    \n",
    "    X2 = Extra_network_2(X)\n",
    "    \n",
    "    X = Inception_block(X, 256, (160, 320), (32, 128), 128)\n",
    "    X = MaxPooling2D(pool_size = 3, strides = 2)(X)\n",
    "    \n",
    "    return X, X1, X2\n",
    "\n",
    "def layer_3(X):\n",
    "    X = Inception_block(X, 64, (96, 128), (16, 32), 32)\n",
    "    X = Inception_block(X, 128, (128, 192), (32, 96), 64)\n",
    "    X = MaxPooling2D(pool_size= (3,3), strides = 2)(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def layer_2(X):\n",
    "    X = Conv2D(filters = 64, \n",
    "               kernel_size = 1, \n",
    "               strides = 1, \n",
    "               padding = 'same', \n",
    "               activation = 'relu')(X)\n",
    "    \n",
    "    X = Conv2D(filters = 192, \n",
    "               kernel_size = 3, \n",
    "               padding = 'same', \n",
    "               activation = 'relu')(X)\n",
    "    \n",
    "    X = MaxPooling2D(pool_size= 3, strides = 2)(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "def load_GoogLeNet():\n",
    "    input_layer = Input(shape = input_shape)\n",
    "    \n",
    "    X = Conv2D(64, kernel_size = 7, strides = 2, \n",
    "               padding = 'valid', activation = 'relu')(input_layer)\n",
    "    \n",
    "    X = MaxPooling2D(pool_size = 3, strides = 2)(X)\n",
    "    \n",
    "    X = layer_2(X)\n",
    "    X = layer_3(X)\n",
    "    X, X1, X2 = layer_4(X)\n",
    "\n",
    "    X = Inception_block(X, 256, (160, 320), (32, 128), 128)\n",
    "    X = Inception_block(X, 384, (192, 384), (48, 128), 128)\n",
    "\n",
    "    X = GlobalAveragePooling2D()(X)\n",
    "    X = Dropout(0.6)(X)\n",
    "    \n",
    "    X = Dense(n_classes, activation = final_activation, name=\"output3\")(X)\n",
    "  \n",
    "    model = Model(input_layer, [X, X1, X2], name = 'GoogLeNet')\n",
    "\n",
    "    return model\n",
    "\n",
    "load_GoogLeNet().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DenseNet121**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import DenseNet121\n",
    "\n",
    "def load_DenseNet121():\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    baseModel = DenseNet121(pooling='avg',\n",
    "                            include_top=False, \n",
    "                            input_tensor=input_tensor)\n",
    "    \n",
    "    model = FCLayers(baseModel)\n",
    "    return model\n",
    "\n",
    "load_DenseNet121().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def getMetrics(name, type_):\n",
    "    if name == 'GoogLeNet':\n",
    "        if type_ == 'accuracy':\n",
    "            return 'output3_accuracy'\n",
    "        if type_ == 'loss':\n",
    "            return 'output3_loss'\n",
    "        if type_ == 'val_accuracy':\n",
    "            return 'val_output3_accuracy'\n",
    "        if type_ == 'val_loss':\n",
    "            return 'val_output3_loss'\n",
    "        \n",
    "    else:\n",
    "        if type_ == 'accuracy':\n",
    "            return 'accuracy'\n",
    "        if type_ == 'loss':\n",
    "            return 'loss'\n",
    "        if type_ == 'val_accuracy':\n",
    "            return 'val_accuracy'\n",
    "        if type_ == 'val_loss':\n",
    "            return 'val_loss'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Call Backs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "id": "d65LnuRPnjQJ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "          \n",
    "EPOCHS = 120\n",
    "patience = 3\n",
    "\n",
    "start_lr = 0.00001\n",
    "min_lr = 0.00001\n",
    "max_lr = 0.00005\n",
    "\n",
    "rampup_epochs = 5\n",
    "sustain_epochs = 0\n",
    "exp_decay = .8\n",
    "        \n",
    "def lrfn(epoch):\n",
    "    if epoch < rampup_epochs:\n",
    "        return (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n",
    "    elif epoch < rampup_epochs + sustain_epochs:\n",
    "        return max_lr\n",
    "    else:\n",
    "        return (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n",
    "        \n",
    "def getCallbacks(name):\n",
    "    class myCallback(Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if ((logs.get(getMetrics(name,'accuracy'))>=0.999)):\n",
    "                print(\"\\nLimits Reached cancelling training!\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "            \n",
    "    end_callback = myCallback()\n",
    "\n",
    "    lr_plat = ReduceLROnPlateau(patience = 2, mode = 'min')\n",
    "\n",
    "    lr_callback = LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=False)\n",
    "\n",
    "    early_stopping = EarlyStopping(patience = patience, monitor=getMetrics(name, 'val_loss'),\n",
    "                                 mode='min', restore_best_weights=True, \n",
    "                                 verbose = 1, min_delta = .00075)\n",
    "\n",
    "\n",
    "    checkpoint_filepath = name + '_Weights.h5'\n",
    "\n",
    "    model_checkpoints = ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                        save_weights_only=True,\n",
    "                                        monitor=getMetrics(name, 'val_loss'),\n",
    "                                        mode='min',\n",
    "                                        verbose = 1,\n",
    "                                        save_best_only=True)\n",
    "\n",
    "    import datetime\n",
    "    log_dir=\"logs/fit/\" + '_' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")  \n",
    "    tensorboard_callback = TensorBoard(log_dir = log_dir, write_graph=True, histogram_freq=1)\n",
    "\n",
    "    return [end_callback, \n",
    "             lr_callback, \n",
    "             model_checkpoints,\n",
    "             early_stopping,\n",
    "             #tensorboard_callback,\n",
    "             lr_plat\n",
    "            ]\n",
    "\n",
    "GoogLeNet_callbacks = getCallbacks('GoogLeNet')\n",
    "callbacks = getCallbacks('DenseNet121')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ji2ENz2JrMNL"
   },
   "source": [
    "## **Compile** and **Fit Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pIdErKBrRmGq"
   },
   "outputs": [],
   "source": [
    "def CompileModel(name, model):\n",
    "    if name == 'GoogLeNet':\n",
    "        model.compile(optimizer='adam', loss=entropy, metrics={\"output1\":\"accuracy\", \"output2\":\"accuracy\", \"output3\":\"accuracy\"})\n",
    "    else:\n",
    "        model.compile(optimizer='adam', loss=entropy, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def FitModel(model, name):\n",
    "    callbacks_ = callbacks\n",
    "    if name == 'GoogLeNet':\n",
    "        callbacks_ = GoogLeNet_callbacks\n",
    "    history = model.fit(train_generator, \n",
    "                        epochs=EPOCHS,\n",
    "                        callbacks=callbacks_,\n",
    "                        validation_data = val_generator,\n",
    "                        steps_per_epoch=(len(train_generator.labels) / 80),\n",
    "                        validation_steps=(len(val_generator.labels) / 80),\n",
    "                       )\n",
    "    \n",
    "    model.load_weights(name + '_Weights.h5')\n",
    "\n",
    "    final_accuracy_avg = np.mean(history.history[getMetrics(name, \"val_accuracy\")][-5:])\n",
    "\n",
    "    final_loss = history.history[getMetrics(name, \"val_loss\")][-1]\n",
    "  \n",
    "    group = {history: 'history', name: 'name', model: 'model', final_accuracy_avg:'acc', final_loss: 'loss'}\n",
    "\n",
    "    print('\\n')\n",
    "    print('---'*15)\n",
    "    print(name,' Model')\n",
    "    print('Total Epochs :', len(history.history[getMetrics(name, 'loss')]))    \n",
    "    print('Restoring best Weights')\n",
    "    \n",
    "    index = (len(history.history[getMetrics(name, 'loss')]) - (patience + 1))\n",
    "    print('---'*15)\n",
    "    print('Best Epoch :', index)\n",
    "    print('---'*15)\n",
    "    \n",
    "    train_accuracy = history.history[getMetrics(name, 'accuracy')][index]\n",
    "    train_loss = history.history[getMetrics(name, 'loss')][index]\n",
    "    \n",
    "    val_accuracy = history.history[getMetrics(name, 'val_accuracy')][index]\n",
    "    val_loss = history.history[getMetrics(name, 'val_loss')][index]\n",
    "\n",
    "    print('Accuracy on train:', train_accuracy,\n",
    "          '\\tLoss on train:', train_loss)\n",
    "    \n",
    "    print('Accuracy on val:', val_accuracy ,\n",
    "          '\\tLoss on val:', val_loss)\n",
    "    print('---'*15)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "id": "b61RKPdsAjSu",
    "outputId": "4ec3d66d-aa26-4704-d0c2-953099174f31"
   },
   "outputs": [],
   "source": [
    "def BuildModel(name):\n",
    "    if name == 'GoogLeNet':\n",
    "        prepared_model = load_GoogLeNet() \n",
    "    if name == 'DenseNet121':\n",
    "        prepared_model = load_DenseNet121()\n",
    "        \n",
    "    compiled_model = CompileModel(name, prepared_model)\n",
    "    return compiled_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training GoogLeNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "g_compiled_model = BuildModel('GoogLeNet')\n",
    "g_model, g_history = FitModel(g_compiled_model, 'GoogLeNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training DenseNet121**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "d_compiled_model = BuildModel('DenseNet121')\n",
    "d_model, d_history = FitModel(d_compiled_model, 'DenseNet121')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Evaluation on the TestSet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def print_graph(item, index, history):\n",
    "    plt.figure()\n",
    "    train_values = history.history[item][0:index]\n",
    "    plt.plot(train_values)\n",
    "    test_values = history.history['val_' + item][0:index]\n",
    "    plt.plot(test_values)\n",
    "    plt.legend(['training','validation'])\n",
    "    plt.title('Training and validation '+ item)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "    plot = '{}.png'.format(item)\n",
    "    plt.savefig(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, plot_roc_curve, accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "def test_set_results(pred_value, n=1):    \n",
    "    y_test = test_generator.labels\n",
    "    X_test, _ = test_generator.next()\n",
    "    \n",
    "    corr_pred = metrics.confusion_matrix(y_test, pred_value)\n",
    "    fig=plt.figure(figsize=(10, 8))\n",
    "    ax = plt.axes()\n",
    "    \n",
    "    sns.heatmap(corr_pred,annot=True, fmt=\"d\",cmap=\"Purples\", xticklabels=CATEGORIES, yticklabels=CATEGORIES)\n",
    "    ax.set_title('Dense Output {}'.format(n))\n",
    "    plt.show()\n",
    "    \n",
    "    n_correct = np.int(corr_pred[0][0] + corr_pred[1][1] + corr_pred[2][2])\n",
    "    print('...'*15)\n",
    "\n",
    "    print('> Correct Predictions:', n_correct)\n",
    "    \n",
    "    n_wrongs = len(y_test) - n_correct\n",
    "    print('> Wrong Predictions:', n_wrongs)\n",
    "    print('...'*15)\n",
    "    \n",
    "    print(classification_report(test_generator.labels, pred_value, target_names=CATEGORIES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResults(name, model):\n",
    "    predictions = model.predict(test_generator, verbose=1)\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    test_set_results(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_summary(model, history, name):\n",
    "    index = (len(history.history[getMetrics(name, 'loss')]) - (patience + 1))\n",
    "    print('Best Epochs: ', index)\n",
    "    \n",
    "    if name == 'GoogLeNet':\n",
    "        results = model.evaluate(test_generator, verbose=1)\n",
    "        loss, output3_loss, output1_loss, output2_loss, output3_accuracy, output1_accuracy, output2_accuracy = results\n",
    "        \n",
    "        for i in range(3):\n",
    "            n = i + 1\n",
    "            out_layer = 'Output Layer {}'.format(n)\n",
    "            \n",
    "            if n == 1:\n",
    "                test_accuracy = output1_accuracy\n",
    "                test_loss = output1_loss\n",
    "\n",
    "            if n == 2:\n",
    "                test_accuracy = output2_accuracy\n",
    "                test_loss = output2_loss\n",
    "                \n",
    "            if n == 3:\n",
    "                test_accuracy = output3_accuracy\n",
    "                test_loss = output3_loss\n",
    "                \n",
    "                \n",
    "            output_name = 'output{}_'.format(n)\n",
    "            train_accuracy, train_loss = history.history[output_name + 'accuracy'][index], history.history[output_name + 'loss'][index]\n",
    "            \n",
    "  \n",
    "            print_graph(output_name + 'loss', index, history)\n",
    "            print_graph(output_name + 'accuracy', index, history)\n",
    "        \n",
    "            print('---'*15)  \n",
    "            print('GoogLeNet Dense output {}:'.format(n))\n",
    "            \n",
    "            print('> Accuracy on train :'.format(out_layer), train_accuracy, \n",
    "                  '\\tLoss on train:',train_loss)\n",
    "        \n",
    "            print('> Accuracy on test :'.format(out_layer), test_accuracy,\n",
    "                  '\\tLoss on test:',test_loss)\n",
    "            \n",
    "            print('---'*15)\n",
    "            print('> predicting test')\n",
    "            print('---'*15)\n",
    "            \n",
    "            predictions = model.predict(test_generator, verbose=1)\n",
    "            preds = np.argmax(predictions[i], axis=1)\n",
    "            test_set_results(preds, n)\n",
    "                \n",
    "    else:\n",
    "        test_loss, test_accuracy = model.evaluate(test_generator, verbose=1)\n",
    "        \n",
    "        train_accuracy = history.history['accuracy'][index]\n",
    "        train_loss = history.history['loss'][index]\n",
    "\n",
    "        print_graph('loss', index, history)\n",
    "        print_graph('accuracy', index, history)\n",
    "        \n",
    "        print('---'*15) \n",
    "        print(name)\n",
    "        print('> Accuracy on train:',train_accuracy, \n",
    "              '\\tLoss on train:',train_loss)\n",
    "        \n",
    "        print('> Accuracy on test:',test_accuracy,\n",
    "              '\\tLoss on test:',test_loss)\n",
    "        \n",
    "        print('---'*15)\n",
    "        print('> predicting test')\n",
    "        print('---'*15)\n",
    "        \n",
    "        printResults(name, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **GoogLeNet Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary(g_model, g_history, 'GoogLeNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DenseNet121 Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary(d_model, d_history, 'DenseNet121')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Saving Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_model.save('GoogLeNet_model.h5')\n",
    "FileLink(r'./GoogLeNet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model.save('DenseNet121_model.h5')\n",
    "FileLink(r'./DenseNet121_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Deployed model**\n",
    "\n",
    "+ **Models**: DenseNet121\n",
    "+ **Size**: 85.9 MB\n",
    "+ **Build With**: React Native\n",
    "+ **Supported Versions**: ANDROID, IOS, WEB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src='https://model-tester.web.app/covid_19', width='100%', height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
